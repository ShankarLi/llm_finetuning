# Production Sentiment Analysis System

A comprehensive, production-ready machine learning pipeline for sentiment analysis featuring advanced hyperparameter optimization, experiment tracking, and RESTful API deployment.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION SENTIMENT ANALYSIS SYSTEM         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Data Layer    â”‚  â”‚  Training Layer â”‚  â”‚  Serving Layer  â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ â€¢ HuggingFace   â”‚  â”‚ â€¢ Optuna        â”‚  â”‚ â€¢ Flask API     â”‚ â”‚
â”‚  â”‚ â€¢ Preprocessing â”‚  â”‚ â€¢ MLflow        â”‚  â”‚ â€¢ Swagger UI    â”‚ â”‚
â”‚  â”‚ â€¢ Caching       â”‚  â”‚ â€¢ Validation    â”‚  â”‚ â€¢ Monitoring    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                    â”‚                    â”‚         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                 â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                Storage & Monitoring                     â”‚   â”‚
â”‚  â”‚ â€¢ Model Artifacts  â€¢ Experiment Logs  â€¢ Metrics       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¬ Machine Learning Pipeline

### Data Flow Diagram
```
HuggingFace Dataset â†’ Text Preprocessing â†’ Feature Extraction â†’ Model Training â†’ Evaluation â†’ Deployment
       â†“                      â†“                    â†“              â†“           â†“          â†“
   â€¢ Cache Data         â€¢ Clean Text        â€¢ TF-IDF         â€¢ Optuna      â€¢ Test     â€¢ REST API
   â€¢ Validation         â€¢ Tokenization      â€¢ N-grams        â€¢ 5-Fold CV   â€¢ Metrics  â€¢ Monitoring
   â€¢ Train/Val/Test     â€¢ Lemmatization     â€¢ Vectorization  â€¢ MLflow      â€¢ Reports  â€¢ Swagger
```

### Algorithm Components

#### 1. **Text Preprocessing Pipeline**
- **URL/Email Removal**: Regular expressions to clean social media artifacts
- **Tokenization**: NLTK word tokenization
- **Lemmatization**: WordNet lemmatizer for word normalization
- **Stop Word Removal**: English stop words filtering
- **N-gram Generation**: Unigram, bigram, trigram feature extraction

#### 2. **Feature Engineering**
- **TF-IDF Vectorization**: Term Frequency-Inverse Document Frequency
- **Feature Selection**: Max features optimization (1K-10K range)
- **Document Frequency Filtering**: Min/max document frequency thresholds
- **Sparse Matrix Optimization**: Memory-efficient storage

#### 3. **Machine Learning Models**
- **Primary**: Logistic Regression with L2 regularization
- **Solver Options**: LBFGS (small datasets), SAGA (large datasets)
- **Class Balancing**: Automatic class weight adjustment
- **Hyperparameter Space**:
  ```python
  {
      'max_features': (1000, 10000),
      'ngram_range': [(1,1), (1,2), (1,3)],
      'min_df': (1, 10),
      'max_df': (0.7, 1.0),
      'C': (0.01, 100),  # Log scale
      'solver': ['lbfgs', 'saga'],
      'max_iter': (500, 2000),
      'class_weight': [None, 'balanced']
  }
  ```

#### 4. **Optimization Framework**
- **Optuna TPE Sampler**: Tree-structured Parzen Estimator
- **Bayesian Optimization**: Intelligent hyperparameter search
- **Pruning**: Median pruner for early stopping
- **Cross-Validation**: 5-fold stratified CV for robust evaluation
- **Multi-objective**: F1-macro score optimization

#### 5. **Experiment Tracking**
- **MLflow Integration**: Experiment logging and model versioning
- **Artifact Storage**: Model serialization and metadata
- **Metric Tracking**: Performance metrics across trials
- **Parameter Logging**: Hyperparameter history

## ğŸš€ Quick Start Guide

### Prerequisites
```bash
# System Requirements
Python 3.9+
4GB+ RAM
2GB+ Disk Space
```

### Installation
```bash
# 1. Clone Repository
git clone https://github.com/your-repo/sentiment-analysis
cd sentiment-analysis

# 2. Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# 3. Install Dependencies
pip install -r requirements.txt

# 4. Verify Installation
python -c "import nltk, sklearn, optuna, mlflow; print('âœ… All dependencies installed')"
```

### Training the Model
```bash
# Start Complete Training Pipeline
python train_production_model.py

# Expected Output:
# âœ… Dataset loaded: 30,000+ samples
# ğŸ”§ Optimization: 75 trials
# ğŸ“Š Best F1-score: ~0.697
# â±ï¸ Training time: ~45 minutes
# ğŸ’¾ Model saved: output/production_sentiment_model_*.pkl
```

### Starting the API
```bash
# Production Server
python production_api.py

# Expected Output:
# âœ… Production model loaded
# ğŸ“Š Model accuracy: 0.6940
# ğŸ¯ Model F1-score: 0.6979
# ğŸš€ Server running on http://0.0.0.0:5000
```

### Using Docker
```bash
# Build Image
docker build -t sentiment-api .

# Run Container
docker run -p 5000:5000 sentiment-api

# Health Check
curl http://localhost:5000/health
```

## ğŸ“Š Model Performance

### Current Production Model Metrics
```
Test Accuracy:  69.40%
Test F1-Macro:  69.79%
Val F1-Score:   69.74%
CV Score:       68.52%

Class Distribution:
â”œâ”€â”€ Positive: 40.0% (8,507 samples)
â”œâ”€â”€ Neutral:  31.4% (6,690 samples)
â””â”€â”€ Negative: 28.6% (6,132 samples)
```

### Optimization Results
```
Hyperparameter Search:
â”œâ”€â”€ Trials Executed: 75
â”œâ”€â”€ Search Space: 8 dimensions
â”œâ”€â”€ Best Parameters:
â”‚   â”œâ”€â”€ max_features: 8,049
â”‚   â”œâ”€â”€ ngram_range: (1,1)
â”‚   â”œâ”€â”€ min_df: 2
â”‚   â”œâ”€â”€ max_df: 0.714
â”‚   â”œâ”€â”€ C: 0.627
â”‚   â”œâ”€â”€ solver: 'saga'
â”‚   â”œâ”€â”€ max_iter: 962
â”‚   â””â”€â”€ class_weight: 'balanced'
â””â”€â”€ Optimization Time: ~43 minutes
```

## ğŸ”— API Documentation

### Base URL
```
http://localhost:5000
```

### Authentication
Currently no authentication required (add for production deployment)

### Endpoints

#### 1. Single Prediction
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "This product is amazing!"}'

# Response:
{
  "sentiment": "positive",
  "confidence": 0.945,
  "model_version": "20250919_182637",
  "probabilities": {
    "positive": 0.945,
    "negative": 0.032,
    "neutral": 0.023
  }
}
```

#### 2. Batch Prediction
```bash
curl -X POST http://localhost:5000/batch-predict \
  -H "Content-Type: application/json" \
  -d '{"texts": ["Great product!", "Terrible service", "It'\''s okay"]}'
```

#### 3. Model Information
```bash
curl http://localhost:5000/model-info

# Response includes:
# â€¢ Model metadata
# â€¢ Performance metrics
# â€¢ Training parameters
# â€¢ Dataset statistics
```

#### 4. Usage Statistics
```bash
curl http://localhost:5000/stats

# Response includes:
# â€¢ Request count
# â€¢ Sentiment distribution
# â€¢ Average confidence
# â€¢ Recent predictions
```

#### 5. Health Check
```bash
curl http://localhost:5000/health
```

### Interactive Documentation
Visit `http://localhost:5000` for Swagger UI interface

## ğŸ“ Project Structure

```
sentiment-analysis/
â”œâ”€â”€ ğŸ“ data_cache/              # Cached datasets
â”œâ”€â”€ ğŸ“ logs/                    # Application logs
â”œâ”€â”€ ğŸ“ output/                  # Model artifacts
â”‚   â”œâ”€â”€ production_sentiment_model_*.pkl
â”‚   â”œâ”€â”€ model_metadata_*.json
â”‚   â”œâ”€â”€ label_encoder.pkl
â”‚   â”œâ”€â”€ final_confusion_matrix.png
â”‚   â””â”€â”€ final_metrics.png
â”œâ”€â”€ ğŸ“ templates/
â”‚   â””â”€â”€ swagger.html            # API documentation UI
â”œâ”€â”€ ğŸ“„ data_manager.py          # Data loading & preprocessing
â”œâ”€â”€ ğŸ“„ hyperparameter_tuner.py  # Optuna optimization
â”œâ”€â”€ ğŸ“„ train_production_model.py # Training pipeline
â”œâ”€â”€ ğŸ“„ production_api.py        # Flask REST API
â”œâ”€â”€ ğŸ“„ swagger_config.py        # API specification
â”œâ”€â”€ ğŸ“„ requirements.txt         # Dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile              # Container configuration
â””â”€â”€ ğŸ“„ README.md               # This file
```

## ğŸ› ï¸ Development & Customization

### Adding New Models
```python
# In hyperparameter_tuner.py
def objective_new_model(self, trial, X_train, y_train):
    # Define hyperparameter space
    # Create model pipeline
    # Return cross-validation score
    pass
```

### Custom Preprocessing
```python
# In data_manager.py
def custom_preprocessing(self, text):
    # Add domain-specific cleaning
    # Return processed text
    pass
```

### Monitoring Integration
```python
# Add to production_api.py
@app.route('/metrics')
def prometheus_metrics():
    # Export metrics for Prometheus
    pass
```

## ğŸ”§ Production Deployment

### Environment Variables
```bash
export FLASK_ENV=production
export MODEL_PATH=/app/models/latest
export LOG_LEVEL=INFO
export MAX_WORKERS=4
```

### Gunicorn Configuration
```bash
gunicorn --bind 0.0.0.0:5000 \
         --workers 4 \
         --timeout 120 \
         --worker-class sync \
         --max-requests 1000 \
         production_api:app
```

### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sentiment-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sentiment-api
  template:
    metadata:
      labels:
        app: sentiment-api
    spec:
      containers:
      - name: sentiment-api
        image: sentiment-api:latest
        ports:
        - containerPort: 5000
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
```

## ğŸ“ˆ Monitoring & Maintenance

### Performance Monitoring
- **Latency**: Response time tracking
- **Throughput**: Requests per second
- **Accuracy**: Prediction confidence monitoring
- **Resource Usage**: CPU/Memory utilization

### Model Retraining Triggers
- **Performance Degradation**: F1-score drops below 65%
- **Data Drift**: Input distribution changes
- **Scheduled**: Monthly retraining
- **New Data**: Significant dataset updates

### Logging & Alerts
```python
# Log levels and destinations
INFO    â†’ Application events
WARNING â†’ Performance issues  
ERROR   â†’ Prediction failures
CRITICAL â†’ System failures
```

## ğŸ§ª Testing

### Unit Tests
```bash
pytest tests/ -v --coverage

# Test coverage includes:
# â€¢ Data preprocessing
# â€¢ Model predictions
# â€¢ API endpoints
# â€¢ Error handling
```

### Load Testing
```bash
# Using Apache Bench
ab -n 1000 -c 10 -T 'application/json' \
   -p test_data.json \
   http://localhost:5000/predict
```

### Integration Tests
```bash
# End-to-end pipeline testing
python -m pytest tests/test_integration.py
```

## ğŸ¤ Contributing

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Code formatting
black --line-length 88 .
flake8 --max-line-length 88
```

### Pull Request Process
1. Fork repository
2. Create feature branch
3. Add tests for new features
4. Ensure all tests pass
5. Update documentation
6. Submit pull request

## ğŸ“ Support & Troubleshooting

### Common Issues

#### Model Not Loading
```bash
# Check model files exist
ls -la output/production_sentiment_model_*.pkl

# Verify dependencies
pip check

# Check logs
tail -f logs/production_training.log
```

#### Memory Issues
```bash
# Reduce batch size
export BATCH_SIZE=32

# Use lighter model
export MODEL_TYPE=logistic_regression
```

#### Performance Issues
```bash
# Enable caching
export ENABLE_CACHE=true

# Increase workers
export GUNICORN_WORKERS=8
```

### Contact Information
- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Email**: admin@sentimentapi.com

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- HuggingFace for dataset hosting
- Optuna team for optimization framework
- MLflow for experiment tracking
- scikit-learn community for ML tools

---

**Built with â¤ï¸ for production ML systems**